name: Build Extensions

on:
  workflow_call:
    inputs:
      distro_codename:
        description: "Distribution codename"
        type: string
        required: true
      build_all:
        description: "Build all targets"
        type: boolean
        default: true
      target_to_build:
        description: "Specific target to build for"
        type: string
        required: false
      release_date:
        description: "Release date timestamp"
        type: string
        required: false
      packages_path:
        description: "Path to packages directory"
        type: string
        required: false
      releases_path:
        description: "Path to releases directory"
        type: string
        required: false
  workflow_dispatch:
    inputs:
      distro_codename:
        description: "Distribution codename"
        type: string
        default: "latest/apollo/edge"
      build_all:
        description: "Build all targets"
        type: boolean
        default: true
      target_to_build:
        description: "Select the machine to build"
        type: choice
        required: false
        options:
          - icam-540
          - imx8mp-evk
          - imx91-frdm
          - imx93-frdm
          - imx93-evk
          - intel-x86-64-v2
          - intel-x86-64-v3
          - intel-x86-64-v4
          - qemuarm64
          - qemux86-64
          - reterminal
          - reterminal-dm
          - jetson-orin-nano-devkit
          - jetson-agx-orin-devkit
          - raspberrypi0-2w
          - raspberrypi4
          - raspberrypi5

jobs:
  setup-paths:
    runs-on: avocado-sdk
    if: github.event_name == 'workflow_dispatch'
    outputs:
      release_date: ${{ steps.set-paths.outputs.release_date }}
      packages_path: ${{ steps.set-paths.outputs.packages_path }}
      releases_path: ${{ steps.set-paths.outputs.releases_path }}
    steps:
      - name: Set paths for manual dispatch
        id: set-paths
        run: |
          DISTRO_CODENAME="${{ inputs.distro_codename || github.event.inputs.distro_codename }}"
          REPO_PATH="/home/runner/_repo"

          # Try to find the latest existing release when no timestamp is provided
          if [ -n "${{ inputs.release_date }}" ]; then
            RELEASE_DATE="${{ inputs.release_date }}"
            echo "Using provided release date: $RELEASE_DATE"
          else
            # Find the latest existing release
            RELEASES_BASE="${REPO_PATH}/releases/${DISTRO_CODENAME}"
            if [ -d "$RELEASES_BASE" ]; then
              LATEST_DIR=$(find "$RELEASES_BASE" -maxdepth 1 -type d -not -path "$RELEASES_BASE" -printf '%T@ %p\n' 2>/dev/null | sort -nr | head -1 | cut -d' ' -f2-)
              if [ -n "$LATEST_DIR" ] && [ -d "$LATEST_DIR" ]; then
                RELEASE_DATE=$(basename "$LATEST_DIR")
                echo "Found latest existing release: $RELEASE_DATE"
              else
                echo "Error: No existing releases found in $RELEASES_BASE"
                echo "Please run build-distro first or provide release_date input"
                exit 1
              fi
            else
              echo "Error: Releases directory $RELEASES_BASE doesn't exist"
              echo "Please run build-distro first or provide release_date input"
              exit 1
            fi
          fi

          # Set paths based on found or provided release date
          if [ -n "${{ inputs.packages_path }}" ]; then
            PACKAGES_PATH="${{ inputs.packages_path }}"
          else
            PACKAGES_PATH="${REPO_PATH}/packages/${DISTRO_CODENAME}"
          fi

          if [ -n "${{ inputs.releases_path }}" ]; then
            RELEASES_PATH="${{ inputs.releases_path }}"
          else
            RELEASES_PATH="${REPO_PATH}/releases/${DISTRO_CODENAME}/${RELEASE_DATE}"
          fi

          echo "Final paths for standalone run:"
          echo "  Release date: $RELEASE_DATE"
          echo "  Packages path: $PACKAGES_PATH"
          echo "  Releases path: $RELEASES_PATH"

          echo "release_date=$RELEASE_DATE" >> $GITHUB_OUTPUT
          echo "packages_path=$PACKAGES_PATH" >> $GITHUB_OUTPUT
          echo "releases_path=$RELEASES_PATH" >> $GITHUB_OUTPUT
        env:
          REPO_PATH: "/home/runner/_repo"
          DISTRO_CODENAME: ${{ inputs.distro_codename || github.event.inputs.distro_codename }}

  generate-matrix:
    runs-on: avocado-sdk
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
      extensions_map: ${{ steps.set-matrix.outputs.extensions_map }}
      has_targets: ${{ steps.set-matrix.outputs.has_targets }}
      avocado_version: ${{ steps.get-version.outputs.version }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Get latest avocado-cli release
        id: get-version
        run: |
          # Install jq if not available
          if ! command -v jq &> /dev/null; then
            sudo apt-get update && sudo apt-get install -y jq
          fi

          LATEST_RELEASE=$(curl -s https://api.github.com/repos/avocado-linux/avocado-cli/releases/latest | jq -r '.tag_name')

          if [ "$LATEST_RELEASE" = "null" ] || [ -z "$LATEST_RELEASE" ]; then
            echo "Failed to get latest release version"
            exit 1
          fi

          echo "version=$LATEST_RELEASE" >> $GITHUB_OUTPUT
          echo "Latest avocado-cli version: $LATEST_RELEASE"

      - name: Generate build matrix
        id: set-matrix
        run: |
          # Load all possible targets from centralized targets list
          ALL_TARGETS=($(jq -r '.[]' .github/data/targets.json))

          # Determine which targets to build for
          BUILD_ALL="${{ inputs.build_all || github.event.inputs.build_all }}"
          TARGET_TO_BUILD="${{ inputs.target_to_build || github.event.inputs.target_to_build }}"

          echo "Build all: $BUILD_ALL"
          echo "Target to build: $TARGET_TO_BUILD"

          # Determine the target filter
          if [ "$BUILD_ALL" = "true" ] || [ "$BUILD_ALL" = "True" ]; then
            FILTERED_TARGETS=("${ALL_TARGETS[@]}")
            echo "Building for all targets"
          elif [ -n "$TARGET_TO_BUILD" ]; then
            FILTERED_TARGETS=("$TARGET_TO_BUILD")
            echo "Building for single target: $TARGET_TO_BUILD"
          else
            FILTERED_TARGETS=("${ALL_TARGETS[@]}")
            echo "No specific target specified, building for all targets"
          fi

          # Function to parse YAML supported_targets field (handles both inline and multi-line list formats)
          parse_yaml_supported_targets() {
            local yaml_file="$1"

            if ! grep -q '^supported_targets:' "$yaml_file"; then
              # Field not present, default to all targets
              echo "*"
              return
            fi

            # First, try to get inline value (e.g., "supported_targets: '*'" or "supported_targets: [a, b]")
            local inline_value=$(grep '^supported_targets:' "$yaml_file" | sed 's/supported_targets: *//' | tr -d '"' | tr -d "'" | tr -d ' ')

            if [ -n "$inline_value" ]; then
              # Inline format found
              echo "$inline_value"
              return
            fi

            # Multi-line YAML list format - extract items following "supported_targets:"
            # Handle indented list items like:
            #   supported_targets:
            #     - raspberrypi5
            local targets=$(awk '
              /^supported_targets:/ { in_list=1; next }
              in_list && /^[^ \t-]/ { exit }
              in_list && /^[ \t]*-[ \t]+/ {
                gsub(/^[ \t]*-[ \t]+/, "");
                gsub(/["'"'"']/, "");
                gsub(/[ \t]+$/, "");
                printf "%s,", $0
              }
            ' "$yaml_file" | sed 's/,$//')

            if [ -n "$targets" ]; then
              echo "$targets"
            else
              # No targets found, default to all
              echo "*"
            fi
          }

          # Function to check if extension supports a target
          extension_supports_target() {
            local supported_targets="$1"
            local target="$2"

              if [ "$supported_targets" = "*" ]; then
              return 0
            fi

            # Parse comma-separated targets
            local targets_list=$(echo "$supported_targets" | sed 's/\[//g' | sed 's/\]//g' | sed 's/"//g' | sed "s/'//g" | tr ',' '\n')
            for supported_target in $targets_list; do
              supported_target=$(echo "$supported_target" | xargs)
              if [ "$supported_target" = "$target" ]; then
                return 0
                      fi
                    done
            return 1
          }

          # Build extensions map: { "extension_name": { "type": "regular|bsp", "supported_targets": "..." }, ... }
          declare -A extensions_info

          # Process each regular extension directory
          for ext_dir in extensions/*/; do
            if [ -d "$ext_dir" ] && [ -f "$ext_dir/avocado.yaml" ]; then
              extension=$(basename "$ext_dir")
              supported_targets=$(parse_yaml_supported_targets "$ext_dir/avocado.yaml")
              extensions_info["$extension"]="regular:$supported_targets"
              echo "Extension $extension (regular): supported_targets=$supported_targets"
            fi
          done

          # Process each BSP extension directory
          for bsp_dir in bsp/*/; do
            if [ -d "$bsp_dir" ] && [ -f "$bsp_dir/avocado.yaml" ]; then
              bsp_name=$(basename "$bsp_dir")
              extension="bsp-$bsp_name"
              supported_targets=$(parse_yaml_supported_targets "$bsp_dir/avocado.yaml")
              extensions_info["$extension"]="bsp:$supported_targets"
              echo "Extension $extension (bsp): supported_targets=$supported_targets"
            fi
          done

          # Create extensions_map JSON for use in build job
          extensions_map_json="{"
          first=true
          for ext in "${!extensions_info[@]}"; do
            IFS=':' read -r type supported_targets <<< "${extensions_info[$ext]}"
            if [ "$first" = true ]; then
              first=false
            else
              extensions_map_json+=","
            fi
            extensions_map_json+="\"$ext\":{\"type\":\"$type\",\"supported_targets\":\"$supported_targets\"}"
          done
          extensions_map_json+="}"

          echo "Extensions map:"
          echo "$extensions_map_json" | jq '.'

          # Create target-based matrix (one job per target, not per extension)
          # This allows scaling to 256 targets with unlimited extensions
          matrix_includes=()
          for target in "${FILTERED_TARGETS[@]}"; do
            # Count extensions that support this target
            ext_count=0
            for ext in "${!extensions_info[@]}"; do
              IFS=':' read -r type supported_targets <<< "${extensions_info[$ext]}"
              if extension_supports_target "$supported_targets" "$target"; then
                ext_count=$((ext_count + 1))
              fi
            done
            echo "Target $target: $ext_count extensions to build"
            matrix_includes+=("{\"target\": \"$target\"}")
          done

          # Create JSON matrix
          matrix_json="["
          for i in "${!matrix_includes[@]}"; do
            if [ $i -gt 0 ]; then
              matrix_json+=","
            fi
            matrix_json+="${matrix_includes[$i]}"
          done
          matrix_json+="]"

          echo "Generated target matrix (${#matrix_includes[@]} targets):"
          echo "$matrix_json" | jq '.'

          # Output whether we have targets to build
          if [ ${#matrix_includes[@]} -gt 0 ]; then
            echo "has_targets=true" >> $GITHUB_OUTPUT
          else
            echo "has_targets=false" >> $GITHUB_OUTPUT
            echo "WARNING: No targets to build!"
          fi

          echo "matrix={\"include\":$matrix_json}" >> $GITHUB_OUTPUT
          echo "extensions_map=$extensions_map_json" >> $GITHUB_OUTPUT

  setup-package-repo:
    needs: setup-paths
    if: always() && !cancelled()
    runs-on: avocado-sdk
    outputs:
      network_name: ${{ steps.setup-service.outputs.network_name }}
      container_name: ${{ steps.setup-service.outputs.container_name }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Docker network and package repo service
        id: setup-service
        run: |
          # Generate a random network name to avoid conflicts
          NETWORK_NAME="avocado-os-build-$(openssl rand -hex 8)"
          echo "network_name=$NETWORK_NAME" >> $GITHUB_OUTPUT

          # Create Docker network
          docker network create "$NETWORK_NAME"
          echo "Created Docker network: $NETWORK_NAME"

          # Build the package repo container if it doesn't exist
          if ! docker image inspect avocadolinux/package-repo:local >/dev/null 2>&1; then
            echo "Building package repo container..."
            docker build -f repo/Containerfile-local -t avocadolinux/package-repo:local repo/
          fi

          # Start the package repo service
          CONTAINER_NAME="avocado-repo-service-$(openssl rand -hex 4)"
          echo "container_name=$CONTAINER_NAME" >> $GITHUB_OUTPUT

          # Local paths for searching (where this script runs)
          LOCAL_CACHE_BASE="/home/runner/_repo"
          LOCAL_PACKAGES_PATH="$LOCAL_CACHE_BASE/packages"
          LOCAL_RELEASES_PATH="$LOCAL_CACHE_BASE/releases"

          # Remote paths for volume mounting (where Docker container will run)
          REMOTE_CACHE_BASE="/mnt/raid/repo"
          REMOTE_PACKAGES_PATH="$REMOTE_CACHE_BASE/packages"
          REMOTE_RELEASES_PATH="$REMOTE_CACHE_BASE/releases"

          # Use provided releases path if available, otherwise find the most recent directory
          # Priority: inputs.releases_path > setup-paths outputs > find latest
          if [ -n "${{ inputs.releases_path }}" ]; then
            # Convert provided path to remote mount path
            LOCAL_RELEASES_DIR="${{ inputs.releases_path }}"
            # Extract the relative path from the base cache directory and convert to remote path
            RELATIVE_PATH=$(echo "$LOCAL_RELEASES_DIR" | sed "s|^$LOCAL_CACHE_BASE/||")
            REMOTE_LATEST_MOUNT_PATH="$REMOTE_CACHE_BASE/$RELATIVE_PATH"
            echo "Using provided releases path: $LOCAL_RELEASES_DIR (local)"
            echo "Will mount: $REMOTE_LATEST_MOUNT_PATH (remote)"
          elif [ -n "${{ needs.setup-paths.result == 'success' && needs.setup-paths.outputs.releases_path || '' }}" ]; then
            # Use path from setup-paths job (for standalone runs)
            LOCAL_RELEASES_DIR="${{ needs.setup-paths.result == 'success' && needs.setup-paths.outputs.releases_path || '' }}"
            if [ -d "$LOCAL_RELEASES_DIR" ]; then
              # Extract the relative path from the base cache directory
              RELATIVE_PATH=$(echo "$LOCAL_RELEASES_DIR" | sed "s|^$LOCAL_CACHE_BASE/||")
              REMOTE_LATEST_MOUNT_PATH="$REMOTE_CACHE_BASE/$RELATIVE_PATH"
              echo "Using provided releases path: $LOCAL_RELEASES_DIR (local)"
              echo "Will mount: $REMOTE_LATEST_MOUNT_PATH (remote)"
            else
              echo "Warning: Provided releases path $LOCAL_RELEASES_DIR does not exist, falling back to search"
              REMOTE_LATEST_MOUNT_PATH="$REMOTE_RELEASES_PATH"
            fi
          else
            # Find the most recent directory in releases/${{ inputs.distro_codename || github.event.inputs.distro_codename }} using local paths
            LOCAL_LATEST_EDGE_PATH="$LOCAL_RELEASES_PATH/${{ inputs.distro_codename || github.event.inputs.distro_codename }}"
            if [ -d "$LOCAL_LATEST_EDGE_PATH" ]; then
              # Find the most recently modified directory
              LATEST_DIR=$(find "$LOCAL_LATEST_EDGE_PATH" -maxdepth 1 -type d -not -path "$LOCAL_LATEST_EDGE_PATH" -printf '%T@ %p\n' 2>/dev/null | sort -nr | head -1 | cut -d' ' -f2-)
              if [ -n "$LATEST_DIR" ] && [ -d "$LATEST_DIR" ]; then
                # Convert local path to remote path for mounting
                LATEST_SUBDIR=$(basename "$LATEST_DIR")
                REMOTE_LATEST_MOUNT_PATH="$REMOTE_CACHE_BASE/releases/${{ inputs.distro_codename || github.event.inputs.distro_codename }}/$LATEST_SUBDIR"
                echo "Found most recent directory: $LATEST_DIR (local)"
                echo "Will mount: $REMOTE_LATEST_MOUNT_PATH (remote)"
              else
                echo "No subdirectories found in $LOCAL_LATEST_EDGE_PATH, using the edge directory itself"
                REMOTE_LATEST_MOUNT_PATH="$REMOTE_CACHE_BASE/releases/${{ inputs.distro_codename || github.event.inputs.distro_codename }}"
              fi
            else
              echo "Warning: $LOCAL_LATEST_EDGE_PATH does not exist, using releases path"
              REMOTE_LATEST_MOUNT_PATH="$REMOTE_RELEASES_PATH"
            fi
          fi

          echo "Using paths:"
          echo "  Local search base: $LOCAL_CACHE_BASE"
          echo "  Remote packages: $REMOTE_PACKAGES_PATH"
          echo "  Remote releases: $REMOTE_RELEASES_PATH"
          echo "  Remote latest: $REMOTE_LATEST_MOUNT_PATH"

          # Start the container in the background

          docker run -d --rm \
            --name "$CONTAINER_NAME" \
            --network "$NETWORK_NAME" \
            -p 8080:80 \
            -e USER_ID=1001 \
            -e GROUP_ID=974 \
            -v "$REMOTE_PACKAGES_PATH:/avocado-repo/packages" \
            -v "$REMOTE_RELEASES_PATH:/avocado-repo/releases" \
            -v "$REMOTE_LATEST_MOUNT_PATH:/avocado-repo/${{ inputs.distro_codename || github.event.inputs.distro_codename }}" \
            avocadolinux/package-repo:local

          echo "Started package repo service container: $CONTAINER_NAME"

          # Give nginx a moment to fully start up
          sleep 5

          # Verify container is still running
          if ! docker ps --filter "name=$CONTAINER_NAME" --filter "status=running" --quiet | grep -q .; then
            echo "ERROR: Package repo container failed to start or exited unexpectedly"
            echo "Container logs:"
            docker logs "$CONTAINER_NAME" || echo "Failed to get container logs"
            exit 1
          fi

          echo "Package repo service setup completed successfully"

  build-extensions:
    needs: [generate-matrix, setup-package-repo, setup-paths]
    if: always() && !cancelled() && needs.setup-package-repo.result == 'success'
    runs-on: avocado-sdk
    strategy:
      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
      fail-fast: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          path: avocado-os
          submodules: recursive

      - run: |
          mkdir -p /mnt/raid/tmp/runs/${{ github.run_id }}/${{ github.run_number }}/${{ runner.name }}
          mv avocado-os /mnt/raid/tmp/runs/${{ github.run_id }}/${{ github.run_number }}/${{ runner.name }}

      - name: Download and install avocado-cli
        run: |
          VERSION="${{ needs.generate-matrix.outputs.avocado_version }}"
          echo "Installing avocado-cli version: $VERSION"

          # Determine architecture
          ARCH=$(uname -m)
          if [ "$ARCH" = "x86_64" ]; then
            BINARY_ARCH="x86_64-unknown-linux-gnu"
          elif [ "$ARCH" = "aarch64" ]; then
            BINARY_ARCH="aarch64-unknown-linux-musl"
          else
            echo "Unsupported architecture: $ARCH"
            exit 1
          fi

          echo "Detected architecture: $ARCH, using binary: $BINARY_ARCH"

          # Download the precompiled binary
          BINARY_NAME="avocado-${VERSION}_${BINARY_ARCH}.tar.gz"
          echo "Downloading: $BINARY_NAME"

          if ! curl -L -o "$BINARY_NAME" "https://github.com/avocado-linux/avocado-cli/releases/download/${VERSION}/${BINARY_NAME}"; then
            echo "Failed to download $BINARY_NAME"
            exit 1
          fi

          # Extract and install
          if ! tar -xzf "$BINARY_NAME"; then
            echo "Failed to extract $BINARY_NAME"
            exit 1
          fi

          if [ ! -f "avocado" ]; then
            echo "avocado binary not found after extraction"
            ls -la
            exit 1
          fi

          sudo cp avocado /usr/local/bin/

          # Verify installation
          avocado --version

      - name: Build all extensions for target
        working-directory: /mnt/raid/tmp/runs/${{ github.run_id }}/${{ github.run_number }}/${{ runner.name }}/avocado-os
        env:
          EXTENSIONS_MAP: ${{ needs.generate-matrix.outputs.extensions_map }}
        run: |
          TARGET="${{ matrix.target }}"
          echo "=========================================="
          echo "Building all extensions for target: $TARGET"
          echo "=========================================="

          # Configure avocado to use the shared package repo service container
          export AVOCADO_SDK_REPO_URL="http://${{ needs.setup-package-repo.outputs.container_name }}"
          export AVOCADO_CONTAINER_NETWORK="${{ needs.setup-package-repo.outputs.network_name }}"
          export AVOCADO_SDK_REPO_RELEASE="${{ inputs.distro_codename || github.event.inputs.distro_codename }}"
          echo "Using package repo URL: $AVOCADO_SDK_REPO_URL"
          echo "Using Docker network: $AVOCADO_CONTAINER_NETWORK"
          echo "Using SDK repo release: $AVOCADO_SDK_REPO_RELEASE"

          # Function to check if extension supports this target
          extension_supports_target() {
            local supported_targets="$1"
            local target="$2"

            if [ "$supported_targets" = "*" ]; then
              return 0
            fi

            # Parse comma-separated targets
            local targets_list=$(echo "$supported_targets" | sed 's/\[//g' | sed 's/\]//g' | sed 's/"//g' | sed "s/'//g" | tr ',' '\n')
            for supported_target in $targets_list; do
              supported_target=$(echo "$supported_target" | xargs)
              if [ "$supported_target" = "$target" ]; then
                return 0
              fi
            done
            return 1
          }

          # Parse extensions map and build each extension that supports this target
          EXTENSIONS=$(echo "$EXTENSIONS_MAP" | jq -r 'keys[]')

          built_extensions=()
          failed_extensions=()
          skipped_extensions=()

          for extension in $EXTENSIONS; do
            ext_type=$(echo "$EXTENSIONS_MAP" | jq -r --arg ext "$extension" '.[$ext].type')
            supported_targets=$(echo "$EXTENSIONS_MAP" | jq -r --arg ext "$extension" '.[$ext].supported_targets')

            # Check if this extension supports our target
            if ! extension_supports_target "$supported_targets" "$TARGET"; then
              echo ""
              echo "--- Skipping $extension (does not support $TARGET) ---"
              skipped_extensions+=("$extension")
              continue
            fi

            echo ""
            echo "=========================================="
            echo "Building extension: $extension (type: $ext_type) for target: $TARGET"
            echo "=========================================="

          # Determine extension directory and package name based on type
            if [ "$ext_type" = "bsp" ]; then
              BSP_NAME="${extension#bsp-}"
            EXT_DIR="bsp/$BSP_NAME"
            PACKAGE_NAME="avocado-bsp-$BSP_NAME"
          else
              EXT_DIR="extensions/$extension"
              PACKAGE_NAME="avocado-ext-$extension"
            fi

            if [ ! -d "$EXT_DIR" ]; then
              echo "ERROR: Extension directory $EXT_DIR not found, skipping"
              failed_extensions+=("$extension")
              continue
          fi

          cd "$EXT_DIR"
          echo "Extension directory: $EXT_DIR"
          echo "Package name: $PACKAGE_NAME"

            # Unlock any stale locks before running avocado commands
            echo "Running: avocado unlock"
            avocado unlock || echo "Unlock had issues, continuing..."

            # Clean extension environment before packaging
            echo "Running: avocado ext clean -e $PACKAGE_NAME --target $TARGET"
            avocado ext clean -e "$PACKAGE_NAME" --target "$TARGET" || echo "Extension clean had issues, continuing..."

            # Package the extension (this handles sdk install, ext install, ext build internally)
            OUTPUT_DIR="$extension-$TARGET"
            echo "Running: avocado ext package -e $PACKAGE_NAME --target $TARGET --out-dir $OUTPUT_DIR --container-arg --network=$AVOCADO_CONTAINER_NETWORK"
            if ! avocado ext package -e "$PACKAGE_NAME" --target "$TARGET" --out-dir "$OUTPUT_DIR" --container-arg "--network=$AVOCADO_CONTAINER_NETWORK"; then
              echo "ERROR: Failed to package extension $extension"
              failed_extensions+=("$extension")
              echo "✗ Extension $extension FAILED for target $TARGET"
            else
              built_extensions+=("$extension")
              echo "✓ Extension $extension packaged successfully for target $TARGET"
            fi

            # Return to workspace root
            cd /mnt/raid/tmp/runs/${{ github.run_id }}/${{ github.run_number }}/${{ runner.name }}/avocado-os
          done

          echo ""
          echo "=========================================="
          echo "Build Summary for target: $TARGET"
          echo "=========================================="
          echo "Built: ${#built_extensions[@]} extensions"
          echo "Failed: ${#failed_extensions[@]} extensions"
          echo "Skipped: ${#skipped_extensions[@]} extensions"

          if [ ${#failed_extensions[@]} -gt 0 ]; then
            echo ""
            echo "Failed extensions: ${failed_extensions[*]}"
            exit 1
          fi

      - name: Copy packages to cache directory
        working-directory: /mnt/raid/tmp/runs/${{ github.run_id }}/${{ github.run_number }}/${{ runner.name }}/avocado-os
        run: |
          TARGET="${{ matrix.target }}"

          # Create the cache directory structure using provided packages path or default
          if [ -n "${{ inputs.packages_path }}" ]; then
            BASE_PACKAGES_PATH="${{ inputs.packages_path }}"
          elif [ -n "${{ needs.setup-paths.result == 'success' && needs.setup-paths.outputs.packages_path || '' }}" ]; then
            BASE_PACKAGES_PATH="${{ needs.setup-paths.result == 'success' && needs.setup-paths.outputs.packages_path || '' }}"
          else
            BASE_PACKAGES_PATH="/home/runner/_repo/packages/${{ inputs.distro_codename || github.event.inputs.distro_codename }}"
          fi

          if [ -n "${{ inputs.releases_path }}" ]; then
            BASE_RELEASES_PATH="${{ inputs.releases_path }}"
          elif [ -n "${{ needs.setup-paths.result == 'success' && needs.setup-paths.outputs.releases_path || '' }}" ]; then
            BASE_RELEASES_PATH="${{ needs.setup-paths.result == 'success' && needs.setup-paths.outputs.releases_path || '' }}"
          else
            BASE_RELEASES_PATH="/home/runner/_repo/releases/${{ inputs.distro_codename || github.event.inputs.distro_codename }}/${{ needs.setup-paths.outputs.release_date }}"
          fi

          # Set up cache directories
          EXT_CACHE_DIR="$BASE_PACKAGES_PATH/target/$TARGET-ext"
          SDK_CACHE_DIR="$BASE_PACKAGES_PATH/sdk/$TARGET"
          EXT_RELEASES_DIR="$BASE_RELEASES_PATH/target/$TARGET-ext"
          SDK_RELEASES_DIR="$BASE_RELEASES_PATH/sdk/$TARGET"

          mkdir -p "$EXT_CACHE_DIR" "$SDK_CACHE_DIR" "$EXT_RELEASES_DIR" "$SDK_RELEASES_DIR"

          echo "Cache directories:"
          echo "  Extension packages: $EXT_CACHE_DIR"
          echo "  SDK packages: $SDK_CACHE_DIR"
          echo "  Extension releases: $EXT_RELEASES_DIR"
          echo "  SDK releases: $SDK_RELEASES_DIR"

          # Find and copy all built RPM packages from all extension output directories
          total_ext_count=0
          total_sdk_count=0

          for output_dir in extensions/*/"*-$TARGET" bsp/*/"bsp-*-$TARGET"; do
            # Use glob expansion to find actual directories
            for dir in $output_dir; do
              if [ -d "$dir" ]; then
                echo "Processing output directory: $dir"

                while IFS= read -r -d '' rpm_file; do
                  rpm_basename=$(basename "$rpm_file")

                  if [[ "$rpm_basename" == *"all_avocadosdk"* ]]; then
                    cp "$rpm_file" "$SDK_CACHE_DIR/"
                    cp "$rpm_file" "$SDK_RELEASES_DIR/"
                    echo "  SDK: $rpm_basename"
                    total_sdk_count=$((total_sdk_count + 1))
                  else
                    cp "$rpm_file" "$EXT_CACHE_DIR/"
                    cp "$rpm_file" "$EXT_RELEASES_DIR/"
                    echo "  EXT: $rpm_basename"
                    total_ext_count=$((total_ext_count + 1))
                  fi
                done < <(find "$dir" -name "*.rpm" -print0 2>/dev/null)
              fi
            done
          done

          # Also check for packages in direct extension directories (different output structure)
          for ext_dir in extensions/* bsp/*; do
            if [ -d "$ext_dir" ]; then
              ext_name=$(basename "$ext_dir")
              output_dir="$ext_dir/$ext_name-$TARGET"

              # For BSP, the output dir name includes bsp- prefix
              if [[ "$ext_dir" == bsp/* ]]; then
                output_dir="$ext_dir/bsp-$ext_name-$TARGET"
              fi

              if [ -d "$output_dir" ]; then
                echo "Processing output directory: $output_dir"

                while IFS= read -r -d '' rpm_file; do
                  rpm_basename=$(basename "$rpm_file")

                  if [[ "$rpm_basename" == *"all_avocadosdk"* ]]; then
                    cp "$rpm_file" "$SDK_CACHE_DIR/"
                    cp "$rpm_file" "$SDK_RELEASES_DIR/"
                    echo "  SDK: $rpm_basename"
                    total_sdk_count=$((total_sdk_count + 1))
                  else
                    cp "$rpm_file" "$EXT_CACHE_DIR/"
                    cp "$rpm_file" "$EXT_RELEASES_DIR/"
                    echo "  EXT: $rpm_basename"
                    total_ext_count=$((total_ext_count + 1))
                  fi
                done < <(find "$output_dir" -name "*.rpm" -print0 2>/dev/null)
              fi
            fi
          done

          echo ""
          echo "Package copying completed for target $TARGET:"
          echo "  $total_ext_count extension packages"
          echo "  $total_sdk_count SDK packages"

      - name: Cleanup avocado state
        working-directory: /mnt/raid/tmp/runs/${{ github.run_id }}/${{ github.run_number }}/${{ runner.name }}/avocado-os
        if: always()
        run: |
          TARGET="${{ matrix.target }}"
          echo "Cleaning up avocado state for target: $TARGET"

          # Clean up all extension directories using avocado clean
          for ext_dir in extensions/* bsp/*; do
            if [ -d "$ext_dir" ]; then
              cd "$ext_dir"
              echo "Cleaning extension directory: $ext_dir"
              avocado clean --target "$TARGET" 2>/dev/null || true
              cd /mnt/raid/tmp/runs/${{ github.run_id }}/${{ github.run_number }}/${{ runner.name }}/avocado-os
            fi
          done

          echo "Cleanup completed for target: $TARGET"

      - name: Cleanup temporary build directory
        if: always()
        run: |
          echo "Cleaning up temporary build directory..."
          TEMP_DIR="/mnt/raid/tmp/runs/${{ github.run_id }}/${{ github.run_number }}/${{ runner.name }}"
          if [ -d "$TEMP_DIR" ]; then
            echo "Removing directory: $TEMP_DIR"
            rm -rf "$TEMP_DIR"
            echo "Temporary build directory cleaned up successfully."
          else
            echo "Temporary directory $TEMP_DIR does not exist, skipping cleanup."
          fi

  cleanup-package-repo:
    needs: [setup-package-repo, build-extensions]
    runs-on: avocado-sdk
    if: always()
    steps:
      - name: Cleanup Docker service
        run: |
          # Stop the package repo container (--rm flag will auto-remove it)
          CONTAINER_NAME="${{ needs.setup-package-repo.outputs.container_name }}"
          if [ -n "$CONTAINER_NAME" ]; then
            echo "Stopping container: $CONTAINER_NAME"
            docker stop "$CONTAINER_NAME" || true
            echo "Container stopped (auto-removed due to --rm flag)"
          fi

          # Remove the Docker network
          NETWORK_NAME="${{ needs.setup-package-repo.outputs.network_name }}"
          if [ -n "$NETWORK_NAME" ]; then
            echo "Removing network: $NETWORK_NAME"
            docker network rm "$NETWORK_NAME" || true
          fi

          echo "Docker cleanup completed"

  update-extension-metadata:
    needs:
      [build-extensions, setup-package-repo, setup-paths, cleanup-package-repo, generate-matrix]
    # Only run if:
    # - build-extensions actually ran (not skipped due to empty matrix)
    # - package repo was available
    # - there were targets to build
    if: |
      always() &&
      !cancelled() &&
      needs.setup-package-repo.result == 'success' &&
      needs.build-extensions.result != 'skipped' &&
      needs.generate-matrix.outputs.has_targets == 'true'
    runs-on: avocado-sdk
    env:
      PACKAGES_PATH: ${{ inputs.packages_path || (needs.setup-paths.result == 'success' && needs.setup-paths.outputs.packages_path) || format('/home/runner/_repo/packages/{0}', inputs.distro_codename || github.event.inputs.distro_codename) }}
      RELEASES_PATH: ${{ inputs.releases_path || (needs.setup-paths.result == 'success' && needs.setup-paths.outputs.releases_path) || format('/home/runner/_repo/releases/{0}', inputs.distro_codename || github.event.inputs.distro_codename) }}
      DISTRO_CODENAME: ${{ inputs.distro_codename || github.event.inputs.distro_codename }}
      AVOCADO_REPO_BASE: "https://repo.avocadolinux.org"
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Validate paths and setup
        run: |
          echo "Using paths:"
          echo "  Packages path: ${{ env.PACKAGES_PATH }}"
          echo "  Releases path: ${{ env.RELEASES_PATH }}"
          echo "  Distro codename: ${{ env.DISTRO_CODENAME }}"

          # If we have a specific releases path from inputs or setup-paths, use it directly
          if [ -n "${{ inputs.releases_path }}" ]; then
            FINAL_RELEASES_PATH="${{ inputs.releases_path }}"
            echo "Using provided releases path: $FINAL_RELEASES_PATH"
          elif [ -n "${{ needs.setup-paths.result == 'success' && needs.setup-paths.outputs.releases_path || '' }}" ]; then
            FINAL_RELEASES_PATH="${{ needs.setup-paths.result == 'success' && needs.setup-paths.outputs.releases_path || '' }}"
            echo "Using setup-paths releases path: $FINAL_RELEASES_PATH"
          else
            # Fallback to finding the most recent directory (for standalone runs)
            RELEASES_BASE="/home/runner/_repo/releases/${{ inputs.distro_codename || github.event.inputs.distro_codename }}"
            if [ -d "$RELEASES_BASE" ]; then
              LATEST_DIR=$(find "$RELEASES_BASE" -maxdepth 1 -type d -not -path "$RELEASES_BASE" -printf '%T@ %p\n' 2>/dev/null | sort -nr | head -1 | cut -d' ' -f2-)
              if [ -n "$LATEST_DIR" ] && [ -d "$LATEST_DIR" ]; then
                FINAL_RELEASES_PATH="$LATEST_DIR"
                echo "Found most recent releases directory: $FINAL_RELEASES_PATH"
              else
                echo "No subdirectories found in $RELEASES_BASE"
                exit 1
              fi
            else
              echo "Releases base directory $RELEASES_BASE does not exist"
              exit 1
            fi
          fi

          echo "FINAL_RELEASES_PATH=$FINAL_RELEASES_PATH" >> $GITHUB_ENV

      - name: Generate extension repository metadata
        run: |
          echo "Generating extension repository metadata"
          echo "Reading packages from: ${{ env.PACKAGES_PATH }}"
          echo "Writing metadata to: $FINAL_RELEASES_PATH"
          echo "Metadata will use relative paths to packages"

          echo "Updating extension packages metadata..."
          ./repo/update-metadata-extensions.sh "${{ env.PACKAGES_PATH }}" "" "$FINAL_RELEASES_PATH"

          echo "Updating SDK packages metadata..."
          ./repo/update-metadata-sdk.sh "${{ env.PACKAGES_PATH }}" "" "$FINAL_RELEASES_PATH"
